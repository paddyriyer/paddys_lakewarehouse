# Technical Documentation

## Enterprise MDM Lakehouse — Claude Opus 4.6 Agentic Architecture

**Version:** 1.0  
**Date:** February 2026  
**Author:** Simultaneous (AI-generated with Claude Opus 4.6)

---

## 1. Introduction

This document provides the complete technical reference for the Enterprise MDM Lakehouse POC — an "Idea to Display" demonstration that takes a business concept (Customer 360 + MDM) from architecture through to fully functional dashboards using Claude Opus 4.6 AI agents.

### 1.1 Problem Statement

Traditional enterprise MDM implementations suffer from:

- **14-18 month timelines** with 25-35 consultant FTEs
- **$4.2-6.8M budgets** dominated by manual pipeline development
- **Fragmented customer data** across SAP, Salesforce, Oracle, and other systems
- **Manual data quality** rules that can't keep pace with data drift
- **Documentation debt** — runbooks and data dictionaries are perpetually outdated

### 1.2 Solution Architecture

Six Claude Opus 4.6 AI agents autonomously generate the entire data platform:

```
Agent 1: ETL Generator    → 50+ PySpark Bronze extraction jobs
Agent 2: DQ Engine        → Great Expectations suites per layer
Agent 3: MDM Matcher      → Jaro-Winkler fuzzy matching engine
Agent 4: dbt Modeler      → Star schema Gold layer models
Agent 5: DAG Builder      → AWS Step Functions orchestration
Agent 6: Doc Writer       → Data dictionaries & runbooks
```

---

## 2. Data Architecture

### 2.1 Medallion Architecture

The Lakehouse follows the Delta Lake medallion pattern on S3:

| Layer | Purpose | S3 Path | Format | Retention |
|-------|---------|---------|--------|-----------|
| **Bronze** | Raw source extracts, append-only | `s3://lakehouse/bronze/` | Delta (Parquet) | 90 days |
| **Silver** | Cleansed, conformed, deduplicated | `s3://lakehouse/silver/` | Delta | 1 year |
| **MDM** | Golden records, match pairs | `s3://lakehouse/mdm/` | Delta | Permanent |
| **Gold** | Star schema for analytics | `s3://lakehouse/gold/` | Delta | Permanent |

**Data Quality Gates** sit between each layer:
- Bronze → Silver: Schema validation, null rate < 5%, no duplicates
- Silver → MDM: Referential integrity, business rule validation
- MDM → Gold: Match score thresholds, completeness > 95%

### 2.2 Star Schema (Gold Layer)

The Gold layer implements a classic Kimball star schema with 6 dimension tables and 5 fact tables:

**Dimensions:**
- `dim_customer` — 500 golden customer records (SCD Type 2)
- `dim_product` — 80 products across 8 categories
- `dim_customer_lifecycle` — Cohort, tenure, churn risk, health scores
- `dim_date` — 762 calendar days (2024-01 to 2026-01)

**Facts:**
- `fact_sales` — 3,500 order transactions
- `fact_interactions` — 6,000 customer touchpoints
- `fact_clickstream` — 25,000 web analytics events
- `fact_pipeline` — 1,200 GTM sales deals
- `fact_fraud_signals` — 450 fraud detection alerts

**Time-Series:**
- `fact_realtime_metrics` — 168 hourly system/business snapshots

**Audit:**
- `mdm_match_pairs` — 200 candidate match pairs with scores

### 2.3 Key Relationships

```
fact_sales.customer_uid      → dim_customer.customer_uid     (Many:1)
fact_sales.product_id        → dim_product.product_id        (Many:1)
fact_sales.order_date        → dim_date.date_key             (Many:1)
fact_interactions.customer_uid → dim_customer.customer_uid   (Many:1)
fact_clickstream.customer_uid  → dim_customer.customer_uid   (Many:1, nullable)
fact_pipeline.customer_uid     → dim_customer.customer_uid   (Many:1)
fact_fraud_signals.customer_uid → dim_customer.customer_uid  (Many:1)
dim_customer_lifecycle.customer_uid → dim_customer.customer_uid (1:1)
```

---

## 3. Data Generation Logic

### 3.1 How We Built the Sample Dataset

The sample data was generated in 6 phases to simulate a realistic enterprise environment:

**Phase 1: Bronze Layer (Source System Extracts)**
- SAP KNA1: 500 customer master records with German field names (KUNNR, NAME1, LAND1, etc.)
- Salesforce Accounts: 400 records with ~60% deliberate overlap against SAP to test MDM matching
- Both include metadata columns: `_source_system`, `_ingestion_ts`

**Phase 2: Gold Star Schema (Post-MDM)**
- `dim_customer`: Generated 500 "golden records" representing the result of MDM merge
- Each record carries `source_systems` (e.g., "SAP+Salesforce+Oracle") showing which systems contributed
- `match_score` reflects the MDM engine's confidence in the merge
- Status distribution weighted: 60% Active, 15% At-Risk, 15% New, 10% Churned

**Phase 3: Transaction Data**
- `fact_sales`: 3,500 orders generated by randomly pairing customers with products
- Realistic discount distribution: 60% no discount, rest 5-20%
- Profit calculated as: `line_total - (quantity × cost_price)`
- `fact_interactions`: 6,000 touchpoints with sentiment weighting: 50% Positive, 35% Neutral, 15% Negative

**Phase 4: Clickstream (Web Analytics)**
- 25,000 events simulating web traffic across 18 page URLs
- 30% anonymous visitors (no `customer_uid`), 70% known customers
- Hourly traffic weighted to business hours (peak: 9am-5pm)
- Conversion tracked: `form_submit` events on `/demo-request`, `/free-trial`, `/checkout`
- 10 referrer sources with UTM campaign tracking

**Phase 5: Customer Lifecycle**
- Derived from `dim_customer` using rule-based lifecycle stage assignment:
  - `Champion`: tenure > 24 months, no activity gap
  - `Loyal`: tenure 12-24 months
  - `Growing`: tenure 3-12 months
  - `At-Risk`: 45-90 day activity gap → churn_risk 0.30-0.65
  - `Dormant`: 90+ day gap → churn_risk 0.60-0.95
  - `Churned`: status == 'Churned' → churn_risk 1.0
- `health_score` = 100 - (churn_risk × 100) ± random noise

**Phase 6: GTM Pipeline + Fraud + Real-Time**
- Pipeline: 1,200 deals across 8 stages, log-normal deal sizes (realistic heavy tail)
- Fraud: 450 alerts across 12 fraud types, severity-weighted risk scores (Critical: μ=90, Low: μ=20)
- Real-time: 168 hourly snapshots with business-hour traffic multipliers

### 3.2 Reproducibility

All generators use `np.random.seed(42)` and `random.seed(42)` for deterministic output. Running `generate_all.py` produces identical data every time.

---

## 4. Pipeline Architecture

### 4.1 SAP Extraction (`sap_extraction.py`)

```
SAP ECC → PyRFC (RFC_READ_TABLE) → PySpark DataFrame → Bronze Delta Lake
```

Key design decisions:
- **PyRFC** for native SAP connectivity (no middleware needed)
- **Secrets Manager** for credential storage (rotated every 90 days)
- **Bronze metadata**: `_ingestion_ts`, `_source_system`, `_batch_id`, `_row_hash`
- **Partitioning**: By `LAND1` (country code) for query performance
- **Write mode**: Append (Bronze is immutable, append-only)

### 4.2 Salesforce Extraction

Two patterns supported:
1. **Batch**: simple_salesforce Bulk API 2.0 with incremental `LastModifiedDate` filter
2. **Real-time CDC**: EventBridge rule on `AccountChangeEvent` → Lambda → S3

### 4.3 MDM Matching Engine (`mdm_matching.py`)

The matching engine uses a three-stage process:

**Stage 1: Blocking (Soundex)**
Reduces O(n²) comparisons by grouping records with matching Soundex codes on the name field. For 500 customers, this reduces ~125,000 comparisons to ~5,000.

**Stage 2: Weighted Composite Scoring**

| Field | Weight | Algorithm | Rationale |
|-------|--------|-----------|-----------|
| Name | 30% | Jaro-Winkler | Handles typos, abbreviations |
| Email | 25% | Exact match (normalized) | High-confidence identifier |
| Phone | 20% | Last 10 digits | Strips formatting differences |
| Address | 15% | Jaro-Winkler | Catches partial address matches |
| Source diversity | 10% | Bonus | Cross-system match = higher confidence |

**Stage 3: Tier Classification**

| Tier | Score Range | Action | Volume |
|------|------------|--------|--------|
| AUTO_MERGE | ≥ 0.92 | Automatic golden record creation | ~58% |
| REVIEW | 0.75 - 0.92 | Data steward queue | ~27% |
| NO_MATCH | < 0.75 | Separate entities | ~15% |

### 4.4 Gold Layer (dbt Models)

The dbt project generates star schema tables from Silver + MDM layers:
- `dim_customer`: SCD Type 2 with `is_current` flag
- `dim_product`: Margin calculation, active flag
- `fact_sales`: Joins customer UID + product + date keys, calculates profit
- Materialization: Delta Lake tables in S3, refreshed via Snowpipe to Snowflake

---

## 5. Claude Agent Architecture

### 5.1 Agentic Loop Pattern

The core loop (`agent_loop.py`) implements Anthropic's tool-use pattern:

```
while not done:
    response = claude.messages.create(tools=TOOLS, messages=history)
    if response.stop_reason == "end_turn":
        return response.text
    for tool_call in response.tool_use_blocks:
        result = HANDLERS[tool_call.name](**tool_call.input)
        history.append(tool_result(result))
```

Key properties:
- **Stateless**: Each API call includes full conversation history
- **Idempotent**: Tool handlers can be retried safely
- **Bounded**: `max_iterations=25` prevents runaway loops
- **Observable**: All tool calls are logged for audit

### 5.2 Tool Registry

Seven enterprise tools are available to all agents:
- `query_database` — SQL execution across SAP HANA, Oracle, Snowflake
- `profile_data_source` — Schema discovery + column statistics
- `write_pipeline_code` — File generation (PySpark, dbt, Airflow)
- `run_tests` — Test execution (pytest, Great Expectations)
- `salesforce_query` — SOQL via Bulk API
- `create_glue_job` — AWS Glue job management
- `delta_lake_operation` — Delta Lake read/write/merge/vacuum

### 5.3 Meta-Agent Orchestration

The orchestrator (`orchestrator.py`) runs all 6 agents in dependency order, passing output context from each agent to the next. Total execution: ~15 minutes for full platform generation.

---

## 6. Dashboard Design

### 6.1 Architecture

The dashboard is a single-file React component using Recharts for visualization. It's designed for Claude.ai Artifacts rendering or any React 18+ environment.

### 6.2 Eight Tabs

| Tab | Purpose | Key Charts |
|-----|---------|-----------|
| **Executive RT** | Live business pulse | Real-time traffic, KPI trends, pipeline funnel |
| **Revenue** | Financial analytics | Monthly rev/profit, category breakdown, geo |
| **Customer 360** | Unified customer view | Status distribution, sentiment, segment radar |
| **Lifecycle** | Customer livability | Stage distribution, churn risk tiers, action cards |
| **GTM Pipeline** | Sales performance | Funnel stages, rep leaderboard, loss reasons |
| **Clickstream** | Web analytics | Conversion funnel, referrer attribution, UTM campaigns |
| **Fraud** | Anomaly monitoring | Severity distribution, detection methods, active alerts |
| **MDM & DQ** | Data governance | Match tiers, source linkage, full schema ERD |

### 6.3 Design Decisions

- **Light theme** with professional color palette for readability
- **AWS Orange (#FF9900)** as primary accent, complemented by semantic colors (green=good, red=alert, purple=data)
- **KPI cards** at top of each tab for instant context
- **Responsive** — all charts use `ResponsiveContainer` for fluid layout
- **Tooltip consistency** — uniform dark tooltip style across all charts

---

## 7. Security Architecture

### 7.1 Defense in Depth

| Layer | Service | Implementation |
|-------|---------|---------------|
| Network | VPC + PrivateLink | No public endpoints; all AWS traffic via VPC endpoints |
| Identity | IAM + Lake Formation | Column-level access control on Delta tables |
| Encryption | KMS CMK | AES-256 at rest (S3, Glue), TLS 1.3 in transit |
| Secrets | Secrets Manager | Auto-rotation for SAP, Salesforce, Oracle credentials |
| Audit | CloudTrail | All API calls logged; 90-day retention |
| Threat | GuardDuty | Anomalous IAM activity detection |

### 7.2 IAM Least Privilege

The Bedrock Claude agent role grants only:
- `bedrock:InvokeModel` on Claude models
- `s3:GetObject/PutObject` on lakehouse bucket
- `glue:StartJobRun/GetJobRun` for pipeline execution
- `secretsmanager:GetSecretValue` for credentials
- `kms:Decrypt` for envelope decryption

---

## 8. Deployment

### Quick Start (5 commands)

```bash
# 1. Infrastructure
cd infra/terraform && terraform init && terraform apply

# 2. Credentials
aws secretsmanager create-secret --name mdm/sap/ecc-production --secret-string '...'

# 3. Generate all code via AI agents
export ANTHROPIC_API_KEY=sk-ant-...
python src/agents/orchestrator.py

# 4. Deploy pipelines
aws s3 sync src/pipelines/ s3://lakehouse/scripts/
aws stepfunctions create-state-machine --name mdm-pipeline --definition file://dag.asl.json

# 5. Launch
aws stepfunctions start-execution --state-machine-arn arn:aws:states:...
```

---

**Built with Claude Opus 4.6 | Simultaneous | February 2026**
